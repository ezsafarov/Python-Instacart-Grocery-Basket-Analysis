{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "088662d8-98d7-4025-8376-f8abb7ae30df",
   "metadata": {},
   "source": [
    "1. Performing the consistency checks covered in this Exercise on  df_prods dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ea5de1-b7bc-4aac-b038-e7274ba157ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6bd8dd-f823-4e25-8666-c860a0802719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the folder path \n",
    "path = r'/Users/emilsafarov/Library/CloudStorage/OneDrive-Personal/CF/A4_Python/Instacart Basket Analysis/02 Data'\n",
    "\n",
    "# importing products.cvs (original) data set \n",
    "df_prods = pd.read_csv(os.path.join(path,'Original data', 'products.csv'), index_col = False)\n",
    "\n",
    "# importing orders_wrangled.cvs \n",
    "df_ords = pd.read_csv(os.path.join(path,'Prepared data', 'orders_wrangled_output4_4.csv'), index_col = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ebcde9-8774-42c1-a9d0-184a65365067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing df.describe() function on df_ords dataframe\n",
    "df_ords.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778570c5-8496-42ec-85a0-af99bed69833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing values in the product data frame\n",
    "df_prods.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcc97ec-afdf-4c59-90ef-1a59e055223b",
   "metadata": {},
   "source": [
    "Obseervation: it seems that there are 16 missing values in product name column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f547f4d6-e05e-4cea-9bcc-541b97189349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a subset data frame showoing missing values in the 'product name' column\n",
    "df_nan = df_prods[df_prods['product_name'].isnull() == True]\n",
    "\n",
    "# dispalying the subset data frame \n",
    "df_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f597c2-58bf-4d4c-828d-42b4e5ce77b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handling missing values by droping them \n",
    "df_prods.dropna(subset = ['product_name'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30a567e-891e-4d29-9e3a-3512c55b168e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding duplicated values\n",
    "df_dups = df_prods[df_prods.duplicated()]\n",
    "\n",
    "# printing duplicated values \n",
    "print(df_dups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199f8a60-16c6-4b11-b6b1-31cece3bd084",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the number of columns before dropping duplicated values\n",
    "df_prods.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c052701-84ae-44da-a7f6-07bb0cf75961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping duplicated values\n",
    "df_prods_no_dups = df_prods.drop_duplicates()\n",
    "\n",
    "#checking the number of columns after dropping duplicated values\n",
    "df_prods_no_dups.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1f925a-5d1a-434c-91ee-af1e163f5618",
   "metadata": {},
   "source": [
    "Observation: as a result 5 duplicated columns has been dropped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6d6a3f-e28f-4015-9915-baf8aac2f0d6",
   "metadata": {},
   "source": [
    "2. Task - describtive analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cc295d-c10b-4b57-b0dd-d6f89ef5f6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conducting descriptive analysis for df_ords\n",
    "\n",
    "df_ords.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288faf9d-64d5-4c14-b0e3-fd57c700d807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping unnesseary index row\n",
    "\n",
    "df_ords = df_ords.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368195e9-e6d7-4f66-92f0-af21b8832b0c",
   "metadata": {},
   "source": [
    "After a deeper analysis, I visualized the distribution of the days_since_prior_order variable using a bar chart in Tableau. The results revealed an unusual pattern: a significant concentration of values at exactly 30 days. This suggests that any gap longer than 30 days has likely been capped at this maximum value. This cap accounts for approximately 60% of the data, which could skew our analysis and reduce its accuracy. Otherwise based on descriptive analysis all data points are within the norms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8910d868-a794-41c2-acdf-b2920e5d2dca",
   "metadata": {},
   "source": [
    "3. and 4. checking for mixed-type data in the data frame using for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8134eb-91ee-409b-8a74-ea59ab649041",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_ords.columns.tolist():\n",
    "  weird = (df_ords[[col]].map(type) != df_ords[[col]].iloc[0].apply(type)).any(axis = 1)\n",
    "  if len (df_ords[weird]) > 0:\n",
    "    print (col)\n",
    "else :\n",
    "    print (\"None of the columns have mix data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23afaa2e-adf6-405d-bbdd-4ba198ef2656",
   "metadata": {},
   "source": [
    "5. and 6. Running a check for missing values in orders dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4426ba0-cc25-4bf7-b5db-171736708e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ords.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad312f9-08f1-4931-b348-0b4ab482ba28",
   "metadata": {},
   "source": [
    "Based on the analysis, 206209 rows are missed in the 'days_since_prior_order' column, which is more than 6% of all defined values. \n",
    "Update: Despite the data in this column being vague, it could still be a useful source for further consideration (like customer segmentation, behavioral trends, etc.). Overall, deleting the column will not add any value to the data; nevertheless, deleting it might result in the loss of valuable information. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d790e41-4d3c-4786-97c3-8fa0e57517c8",
   "metadata": {},
   "source": [
    "7. and 8. Running a check for duplicated values in dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fa94f3-039c-4d6b-92d6-0ba7d865f289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining duplicates\n",
    "df_dups = df_ords[df_ords.duplicated()]\n",
    "\n",
    "# checking the count of duplicates\n",
    "duplicate_count = df_ords.duplicated().sum()\n",
    "\n",
    "print(f\"Total duplicates: {duplicate_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa36ba4a-ebf3-449b-a02c-7418db29b594",
   "metadata": {},
   "source": [
    "Based on analysis there are no duplicates in the df, which is a sign of high accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef0bcb6-2ab6-4fc1-b444-3ed2e39b609d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting manipulated data frames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73347ee-1ed7-43cb-9da4-62d0a1868676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting orders \n",
    "df_ords.to_csv(os.path.join(path, 'Prepared data', 'orders_output_4_5.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31adb5e-66eb-4604-bdab-ae8a2578d57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting products\n",
    "df_prods_no_dups.to_csv(os.path.join(path, 'Prepared data', 'products_output_4_5.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
